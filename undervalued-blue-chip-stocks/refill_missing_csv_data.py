# -*- coding: utf-8 -*-
"""
refill_missing_data.py

ê¸°ì¡´ details_cache CSV íŒŒì¼ì—ì„œ ë¹„ì–´ìˆëŠ” ì¬ë¬´ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì±„ì›Œì£¼ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import time
import math
import random
import warnings
import logging
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from curl_cffi import requests

warnings.filterwarnings("ignore")
logging.getLogger("yfinance").setLevel(logging.CRITICAL)

session = requests.Session(impersonate="chrome")

# ===================== CONFIG =====================
CONFIG = {
    "INPUT_FILE": "details_cache_us_all_20251105_131751.csv",  # ì…ë ¥ íŒŒì¼ëª…
    "OUTPUT_SUFFIX": "_refilled",  # ì¶œë ¥ íŒŒì¼ ì ‘ë¯¸ì‚¬

    # ì¬ì‹œë„ ì„¤ì •
    "MAX_RETRIES": 3,
    "RETRY_DELAY": 1.0,  # ì´ˆ

    # ë³‘ë ¬ ì²˜ë¦¬
    "WORKERS": 1,  # ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜

    # ì§„í–‰ìƒí™© ì¶œë ¥
    "PROGRESS_INTERVAL": 50,  # Nê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥

    # ì–´ë–¤ í•„ë“œê°€ ë¹„ì–´ìˆì„ ë•Œ ë‹¤ì‹œ ìˆ˜ì§‘í• ì§€ (ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ í•„ë“œë“¤)
    "CRITICAL_FIELDS": [
        "Sector", "Industry", "MktCap($B)",
        "PE", "RevYoY", "OpMarginTTM"
    ],

    # ë””ë²„ê¹…
    "VERBOSE": True,
    "SAVE_BACKUP": True,  # ì›ë³¸ íŒŒì¼ ë°±ì—… ì—¬ë¶€
}


# ============== ë°ì´í„° ê²€ì¦ í•¨ìˆ˜ë“¤ (ì›ë³¸ê³¼ ë™ì¼) ==============

def validate_numeric(value, min_val=None, max_val=None, allow_negative=False):
    """ìˆ«ì ê°’ ê²€ì¦"""
    if value is None or (isinstance(value, float) and (math.isnan(value) or math.isinf(value))):
        return None
    try:
        val = float(value)
        if math.isnan(val) or math.isinf(val):
            return None
        if not allow_negative and val < 0:
            return None
        if min_val is not None and val < min_val:
            return None
        if max_val is not None and val > max_val:
            return None
        return val
    except (TypeError, ValueError):
        return None


def validate_percentage(value, min_pct=-100, max_pct=1000):
    return validate_numeric(value, min_val=min_pct, max_val=max_pct, allow_negative=True)


def validate_ratio(value, min_ratio=0, max_ratio=1000):
    return validate_numeric(value, min_val=min_ratio, max_val=max_ratio, allow_negative=False)


def validate_market_cap(value):
    return validate_numeric(value, min_val=1_000_000, max_val=20_000_000_000_000, allow_negative=False)


def validate_price(value):
    return validate_numeric(value, min_val=0.01, max_val=100_000, allow_negative=False)


# ============== ì¬ë¬´ì œí‘œ ìœ í‹¸ í•¨ìˆ˜ë“¤ ==============

REV_ALIASES = ["total revenue", "revenues", "revenue", "net sales", "sales", "total net sales"]
OP_ALIASES = ["operating income", "operating income (loss)", "income from operations", "operating profit", "ebit"]
FCF_ALIASES = ["free cash flow", "free cashflow", "freecashflow"]
EPS_ALIASES = ["diluted eps", "basic eps", "eps (diluted)", "eps (basic)", "earnings per share", "eps"]
NET_INCOME_ALIASES = ["net income", "net income common stockholders"]
DIL_SHARES_ALIASES = ["diluted average shares", "weighted average shares diluted"]


def _find_row(index_like, aliases, exclude=None):
    if index_like is None:
        return None
    exclude = [w.lower() for w in (exclude or [])]
    idx = [str(x).lower() for x in index_like]
    for key in aliases:
        k = key.lower()
        for i, s in enumerate(idx):
            if k in s and not any(x in s for x in exclude):
                return index_like[i]
    return None


def ttm_sum(df, row, n=4):
    if df is None or df.empty or row not in df.index or df.shape[1] < n:
        return None
    cols = sorted(df.columns, reverse=True)[:n]
    try:
        vals = pd.to_numeric(df.loc[row, cols], errors="coerce").fillna(0)
        result = float(vals.sum())
        return result if not math.isnan(result) else None
    except:
        return None


def ttm_yoy_growth(df_q, row):
    if df_q is None or df_q.empty or row not in df_q.index or df_q.shape[1] < 8:
        return None
    cols = sorted(df_q.columns, reverse=True)
    try:
        curr = float(pd.to_numeric(df_q.loc[row, cols[:4]], errors="coerce").fillna(0).sum())
        prev = float(pd.to_numeric(df_q.loc[row, cols[4:8]], errors="coerce").fillna(0).sum())
    except:
        return None
    if prev <= 0:
        return None
    growth = (curr / prev) - 1.0
    return validate_percentage(growth, min_pct=-0.99, max_pct=9.99)


def _safe_df(getter, max_retries=3):
    """DataFrame ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
    for attempt in range(max_retries):
        try:
            df = getter()
            if df is not None and hasattr(df, 'empty') and not df.empty:
                return df
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(0.5 + random.uniform(0, 0.5))
    return None


# ============== PER ê³„ì‚° í•¨ìˆ˜ ==============

def calculate_pe_ratio(ticker, price, info, df_q, df_a):
    """PER ê³„ì‚°"""
    pe_values = []

    # ë°©ë²• 1: infoì—ì„œ ì§ì ‘
    try:
        trailing_pe = info.get("trailingPE")
        forward_pe = info.get("forwardPE")
        if trailing_pe and trailing_pe > 0:
            validated = validate_ratio(trailing_pe, min_ratio=0.1, max_ratio=500)
            if validated:
                pe_values.append(validated)
        if forward_pe and forward_pe > 0:
            validated = validate_ratio(forward_pe, min_ratio=0.1, max_ratio=500)
            if validated:
                pe_values.append(validated)
    except:
        pass

    # ë°©ë²• 2: trailing EPS
    try:
        trailing_eps = info.get("trailingEps")
        if trailing_eps and trailing_eps > 0 and price and price > 0:
            pe_calculated = price / trailing_eps
            if 0 < pe_calculated < 1000:
                pe_values.append(pe_calculated)
    except:
        pass

    # ìœ íš¨í•œ PER ì¤‘ ì¤‘ê°„ê°’ ë°˜í™˜
    valid_pes = [pe for pe in pe_values if pe is not None and 0 < pe < 500]
    if valid_pes:
        return validate_ratio(np.median(valid_pes), min_ratio=0.1, max_ratio=500)

    return None


# ============== ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ ==============

def fetch_missing_data(ticker, price):
    """í‹°ì»¤ì— ëŒ€í•œ ëˆ„ë½ëœ ë°ì´í„° ìˆ˜ì§‘"""
    result = {}

    for attempt in range(CONFIG["MAX_RETRIES"]):
        try:
            t = yf.Ticker(ticker, session=session)
            info = t.get_info() or {}

            if info:
                # ê¸°ë³¸ ì •ë³´
                result["Sector"] = info.get("sector")
                result["Industry"] = info.get("industry")
                result["MktCap($B)"] = round(validate_market_cap(info.get("marketCap")) / 1e9, 2) if info.get(
                    "marketCap") else None

                # ì¬ë¬´ì œí‘œ ê°€ì ¸ì˜¤ê¸°
                q_is = _safe_df(lambda: t.quarterly_income_stmt)
                if q_is is None:
                    q_is = _safe_df(lambda: t.quarterly_financials)

                a_is = _safe_df(lambda: t.income_stmt)
                if a_is is None:
                    a_is = _safe_df(lambda: t.financials)

                cf_q = _safe_df(lambda: t.quarterly_cashflow)
                balance_a = _safe_df(lambda: t.balance_sheet)

                # RevYoY ê³„ì‚°
                if q_is is not None:
                    rev_row = _find_row(q_is.index, REV_ALIASES, exclude=["per share"])
                    if rev_row:
                        result["RevYoY"] = ttm_yoy_growth(q_is, rev_row)

                # OpMarginTTM ê³„ì‚°
                if q_is is not None:
                    rev_row = _find_row(q_is.index, REV_ALIASES, exclude=["per share"])
                    op_row = _find_row(q_is.index, OP_ALIASES)
                    if rev_row and op_row:
                        rev_ttm = ttm_sum(q_is, rev_row, 4)
                        op_ttm = ttm_sum(q_is, op_row, 4)
                        if rev_ttm and op_ttm and rev_ttm > 0:
                            margin = op_ttm / rev_ttm
                            result["OpMarginTTM"] = validate_percentage(margin, min_pct=-1.0, max_pct=1.0)

                # info ê¸°ë°˜ ì§€í‘œë“¤
                result["OperatingMargins(info)"] = validate_percentage(info.get("operatingMargins"), min_pct=-1.0,
                                                                       max_pct=1.0)
                result["ROE(info)"] = validate_percentage(info.get("returnOnEquity"), min_pct=-5.0, max_pct=5.0)
                result["ROA(info)"] = validate_percentage(info.get("returnOnAssets"), min_pct=-5.0, max_pct=5.0)

                # EV/EBITDA
                ev = info.get("enterpriseValue")
                ebitda = info.get("ebitda")
                if ev and ebitda and float(ebitda) > 0:
                    result["EV_EBITDA"] = validate_ratio(float(ev) / float(ebitda), min_ratio=-100, max_ratio=500)

                # PE ê³„ì‚°
                result["PE"] = calculate_pe_ratio(ticker, price, info, q_is, a_is)

                # PEG
                if result.get("PE") and result["PE"] > 0:
                    earnings_growth = info.get("earningsGrowth") or info.get("earningsQuarterlyGrowth")
                    if earnings_growth and earnings_growth > 0:
                        peg = result["PE"] / (earnings_growth * 100)
                        result["PEG"] = validate_ratio(peg, min_ratio=0, max_ratio=100)

                # FCF Yield
                if cf_q is not None:
                    fcf_row = _find_row(cf_q.index, FCF_ALIASES)
                    if fcf_row:
                        fcf_ttm = ttm_sum(cf_q, fcf_row, 4)
                        mktcap = info.get("marketCap")
                        if fcf_ttm and mktcap and float(mktcap) > 0:
                            result["FCF_Yield"] = validate_percentage(fcf_ttm / mktcap, min_pct=-1.0, max_pct=1.0)

                # ê¸°íƒ€ ë¹„ìœ¨ë“¤
                result["PB"] = validate_ratio(info.get("priceToBook"), min_ratio=0, max_ratio=100)
                result["PS"] = validate_ratio(info.get("priceToSalesTrailing12Months"), min_ratio=0, max_ratio=100)
                result["DivYield"] = validate_percentage(info.get("dividendYield"), min_pct=0, max_pct=0.5)
                result["PayoutRatio"] = validate_percentage(info.get("payoutRatio"), min_pct=0, max_pct=2.0)

                # ë² íƒ€ ë° ì†Œìœ  êµ¬ì¡°
                result["Beta"] = validate_numeric(info.get("beta"), min_val=-5, max_val=5, allow_negative=True)
                result["ShortPercent"] = validate_percentage(info.get("shortPercentOfFloat"), min_pct=0, max_pct=1.0)
                result["InsiderOwnership"] = validate_percentage(info.get("heldPercentInsiders"), min_pct=0,
                                                                 max_pct=1.0)
                result["InstitutionOwnership"] = validate_percentage(info.get("heldPercentInstitutions"), min_pct=0,
                                                                     max_pct=1.0)

                # ì„±ê³µí•˜ë©´ ë°˜í™˜
                return result

        except Exception as e:
            if CONFIG["VERBOSE"]:
                print(f"  âš ï¸  {ticker} ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(e)}")

            if attempt < CONFIG["MAX_RETRIES"] - 1:
                time.sleep(CONFIG["RETRY_DELAY"] * (2 ** attempt))

    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
    return result


def refill_row(args):
    """ë‹¨ì¼ í–‰ì˜ ëˆ„ë½ ë°ì´í„° ì±„ìš°ê¸° (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
    idx, row = args
    ticker = row["Ticker"]
    price = row["Price"]

    try:
        # ëˆ„ë½ëœ í•„ë“œ í™•ì¸
        missing_fields = []
        for field in CONFIG["CRITICAL_FIELDS"]:
            if pd.isna(row.get(field)) or row.get(field) == "":
                missing_fields.append(field)

        if not missing_fields:
            return idx, None, "No missing critical fields"

        # ë°ì´í„° ìˆ˜ì§‘
        new_data = fetch_missing_data(ticker, price)

        if new_data:
            return idx, new_data, f"Updated {len([k for k, v in new_data.items() if v is not None])} fields"
        else:
            return idx, None, "No data collected"

    except Exception as e:
        return idx, None, f"Error: {str(e)}"


# ============== ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ ==============

def refill_missing_data_main():
    """ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"""
    print("\n" + "=" * 60)
    print("ğŸ”„ ëˆ„ë½ ë°ì´í„° ì¬ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 60)

    # 1. CSV íŒŒì¼ ì½ê¸°
    input_file = CONFIG["INPUT_FILE"]
    if not os.path.exists(input_file):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        return

    print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {input_file}")
    df = pd.read_csv(input_file)
    print(f"âœ… ì´ {len(df)}ê°œ í–‰ ë¡œë“œë¨")

    # 2. ë°±ì—… ìƒì„±
    if CONFIG["SAVE_BACKUP"]:
        backup_file = input_file.replace(".csv", "_backup.csv")
        df.to_csv(backup_file, index=False)
        print(f"ğŸ’¾ ë°±ì—… ì €ì¥: {backup_file}")

    # 3. ëˆ„ë½ ë°ì´í„° í†µê³„
    print("\nğŸ“Š ëˆ„ë½ ë°ì´í„° í†µê³„:")
    critical_missing = {}
    for field in CONFIG["CRITICAL_FIELDS"]:
        if field in df.columns:
            missing_count = df[field].isna().sum()
            critical_missing[field] = missing_count
            print(f"  - {field}: {missing_count}ê°œ ({missing_count / len(df) * 100:.1f}%)")

    # 4. ì¬ìˆ˜ì§‘ ëŒ€ìƒ ì„ ì •
    needs_refill = df[df[CONFIG["CRITICAL_FIELDS"]].isna().any(axis=1)]
    print(f"\nğŸ¯ ì¬ìˆ˜ì§‘ ëŒ€ìƒ: {len(needs_refill)}ê°œ ì¢…ëª©")

    if len(needs_refill) == 0:
        print("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ì±„ì›Œì ¸ ìˆìŠµë‹ˆë‹¤!")
        return

    # 5. ë³‘ë ¬ ì²˜ë¦¬ë¡œ ë°ì´í„° ìˆ˜ì§‘
    print(f"\nâš™ï¸  {CONFIG['WORKERS']}ê°œ ìŠ¤ë ˆë“œë¡œ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘...")

    tasks = [(idx, row) for idx, row in needs_refill.iterrows()]
    updated_count = 0
    failed_count = 0

    start_time = time.time()

    with ThreadPoolExecutor(max_workers=CONFIG["WORKERS"]) as executor:
        futures = {executor.submit(refill_row, task): task for task in tasks}

        for i, future in enumerate(as_completed(futures), 1):
            idx, new_data, message = future.result()

            if new_data:
                # DataFrame ì—…ë°ì´íŠ¸
                for field, value in new_data.items():
                    if value is not None and field in df.columns:
                        df.at[idx, field] = value
                updated_count += 1
            else:
                failed_count += 1

            # ì§„í–‰ìƒí™© ì¶œë ¥
            if i % CONFIG["PROGRESS_INTERVAL"] == 0 or i == len(tasks):
                elapsed = time.time() - start_time
                rate = i / elapsed if elapsed > 0 else 0
                eta = (len(tasks) - i) / rate if rate > 0 else 0
                print(f"  ğŸ“ˆ ì§„í–‰: {i}/{len(tasks)} ({i / len(tasks) * 100:.1f}%) | "
                      f"ì„±ê³µ: {updated_count} | ì‹¤íŒ¨: {failed_count} | "
                      f"ì†ë„: {rate:.1f}ê°œ/ì´ˆ | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {eta / 60:.1f}ë¶„")

    # 6. ê²°ê³¼ ì €ì¥
    output_file = input_file.replace(".csv", f"{CONFIG['OUTPUT_SUFFIX']}.csv")
    df.to_csv(output_file, index=False)

    elapsed_total = time.time() - start_time

    print("\n" + "=" * 60)
    print("âœ… ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
    print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {elapsed_total / 60:.1f}ë¶„")
    print(f"âœ”ï¸  ì—…ë°ì´íŠ¸ ì„±ê³µ: {updated_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")

    # 7. ê°œì„  í†µê³„
    print("\nğŸ“Š ê°œì„  í†µê³„:")
    for field in CONFIG["CRITICAL_FIELDS"]:
        if field in df.columns:
            before = critical_missing[field]
            after = df[field].isna().sum()
            improved = before - after
            print(f"  - {field}: {before} â†’ {after} (ê°œì„ : {improved}ê°œ, {improved / before * 100:.1f}%)")

    print("=" * 60 + "\n")


if __name__ == "__main__":
    refill_missing_data_main()